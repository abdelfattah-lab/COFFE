###############################################################
### COFFE Drinker: Mass simulation for COFFE Maker record files
###############################################################
# Use Kratos-explorer's coffe_maker.py to generate the required record file.

import os, shutil
import sys
import argparse
import time
import coffe.fpga as fpga
import coffe.spice as spice
import coffe.tran_sizing as tran_sizing
import coffe.utils as utils
import coffe.vpr as vpr
import pandas as pd
import math
from concurrent.futures import ProcessPoolExecutor, as_completed
import traceback

print ("\nCOFFE Drinker\n")
print ("Man is man.")
print ("Without man he is nothing, with man he is all.")
print ("                                   - A Man\n\n")

###############
# Log Functions
###############

def log(message):
    print(f"(!) {message}")
def log_error(message):
    print(f"[ERR] {message}")
    exit()

##################
# Argument Parsing
##################

# Parse the input arguments with argparse
parser = argparse.ArgumentParser()
parser.add_argument('record_file', help="record .csv file generated by coffe_maker.")
parser.add_argument('-f', '--output_file', help="output archive file name; default is 'drinker_archive'", default='drinker_archive')
parser.add_argument('-n', '--no_sizing', help="don't perform transistor sizing", action='store_true')
parser.add_argument('-o', '--opt_type', type=str, choices=["global", "local"], default="global", help="choose optimization type")
parser.add_argument('-s', '--initial_sizes', type=str, default="default", help="path to initial transistor sizes")
parser.add_argument('-m', '--re_erf', type=int, default=1, help="choose how many sizing combos to re-erf")
parser.add_argument('-a', '--area_opt_weight', type=int, default=1, help="area optimization weight")
parser.add_argument('-d', '--delay_opt_weight', type=int, default=1, help="delay optimization weight")
parser.add_argument('-i', '--max_iterations', type=int, default=6, help="max FPGA sizing iterations")
parser.add_argument('-hi', '--size_hb_interfaces', type=float, help="perform transistor sizing only for hard block interfaces", default=0.0)
#arguments for ASIC flow 
parser.add_argument('-ho',"--hardblock_only",help="run only a single hardblock through the asic flow", action='store_true',default=False)
parser.add_argument('-g',"--gen_hb_scripts",help="generates all hardblock scripts which can be run by a user",action='store_true',default=False)
parser.add_argument('-p',"--parallel_hb_flow",help="runs the hardblock flow for current parameter selection in a parallel fashion",action='store_true',default=False)
parser.add_argument('-r',"--parse_pll_hb_flow",help="parses the hardblock flow from previously generated results",action='store_true',default=False)

# quick mode is disabled by default. Try passing -q 0.03 for 3% minimum improvement
parser.add_argument('-q', '--quick_mode', type=float, default=-1.0, help="minimum cost function improvement for resizing")

args = parser.parse_args()

# Check for coffe_maker record
record_file_path = args.record_file
if not os.path.exists(record_file_path):
    log_error("Could not find a record file at {record_file_path}.".format(record_file_path=record_file_path))

###########################
# Main Job
###########################
def job(coffe_params, arch_folder):
  # Redirect stdout and stderr
  sys.stdout = open(os.path.join(arch_folder, 'std.out'), 'w')
  sys.stderr = open(os.path.join(arch_folder, 'std.err'), 'w')

  if(args.hardblock_only):
    # Change to the architecture directory
    for hardblock_params in coffe_params["asic_hardblock_params"]["hardblocks"]:
      hard_block = fpga._hard_block(hardblock_params,False,args)
      os.chdir(arch_folder)
      if(args.gen_hb_scripts):
        hard_block.generate_hb_scripts()
      elif(args.parallel_hb_flow):
        hard_block.generate_top_parallel()
      elif(args.parse_pll_hb_flow):
        hard_block.generate_parallel_results()
      else:
        hard_block.generate_top()
  else:
    is_size_transistors = not args.no_sizing
    size_hb_interfaces = args.size_hb_interfaces

    # Print the options to both terminal and report file
    report_file_path = os.path.join(arch_folder, "report.txt") 
    utils.print_run_options(args, report_file_path)

    # Print architecture and process details to terminal and report file
    utils.print_architecture_params(coffe_params["fpga_arch_params"], report_file_path)

    # Default_dir is the dir you ran COFFE from. COFFE will be switching directories 
    # while running HSPICE, this variable is so that we can get back to our starting point
    default_dir = os.getcwd()

    # Create an HSPICE interface
    spice_interface = spice.SpiceInterface()

    # Record start time
    total_start_time = time.time()

    # Create an FPGA instance
    fpga_inst = fpga.FPGA(coffe_params, args, spice_interface)
                        
    ###############################################################
    ## GENERATE FILES
    ###############################################################

    # Change to the architecture directory
    os.chdir(arch_folder)  

    # Generate FPGA and associated SPICE files
    fpga_inst.generate(is_size_transistors, size_hb_interfaces) 

    # Go back to the base directory
    os.chdir(default_dir)

    # Extract initial transistor sizes from file and overwrite the 
    # default initial sizes if this option was used.
    if args.initial_sizes != "default" :
      utils.use_initial_tran_size(args.initial_sizes, fpga_inst, tran_sizing, coffe_params["fpga_arch_params"]['use_tgate'])

    # Print FPGA implementation details
    report_file = open(report_file_path, 'a')
    fpga_inst.print_details(report_file)  
    report_file.close()

    # Go to architecture directory
    os.chdir(arch_folder)

    ###############################################################
    ## TRANSISTOR SIZING
    ###############################################################

    sys.stdout.flush()

    # Size FPGA transistors
    if is_size_transistors:
        tran_sizing.size_fpga_transistors(fpga_inst, args, spice_interface)                                    
    else:
      # in case of disabling floorplanning there is no need to 
      # update delays before updating area. Tried both ways and 
      # they give exactly the same results
      #fpga_inst.update_delays(spice_interface)

      # same thing here no need to update area before calculating 
      # the lb_height value. Also tested and gave same results
      #fpga_inst.update_area()
      fpga_inst.lb_height = math.sqrt(fpga_inst.area_dict["tile"])
      fpga_inst.update_area()
      fpga_inst.compute_distance()
      fpga_inst.update_wires()
      fpga_inst.update_wire_rc()

      # commented this part to avoid doing floorplannig for
      # a non-sizing run
      #fpga_inst.determine_height()

      fpga_inst.update_delays(spice_interface)

    # Obtain Memory core power
    if coffe_params["fpga_arch_params"]['enable_bram_module'] == 1:
      fpga_inst.update_power(spice_interface)

    # Go back to the base directory
    os.chdir(default_dir)

    # Print out final COFFE report to file
    utils.print_summary(arch_folder, fpga_inst, total_start_time)

    # Return VPR dictionary
    return vpr.get_vpr_dict(fpga_inst)
  
####################################
# Parallel Job Queuing and Execution
####################################

def queue_job(output_dir, i, pair):
    arch_vars, coffe_params = pair

    # Make arch folder
    arch_folder = os.path.join(output_dir, f"arch_{i}")
    if os.path.exists(arch_folder):
       # remove all contents and re-make
       shutil.rmtree(arch_folder)
    os.makedirs(arch_folder)
    
    # Run job
    archive = {**arch_vars, **job(coffe_params, arch_folder)}
    
    print(archive)
    return archive

# Make output directory
output_dir = os.path.abspath(os.path.dirname(record_file_path))
output_dir = os.path.join(output_dir, 'coffe_drinker_out')
os.makedirs(output_dir, exist_ok=True)

# Read in DataFrame
record = pd.read_csv(record_file_path)
executor = ProcessPoolExecutor(max_workers=16)
jobs = [executor.submit(queue_job, output_dir, i, pair) for i, pair in enumerate(utils.load_params_coffe_maker(record_file_path, args))]

# Run all jobs
jobs_count = len(jobs)
print(f"Running {jobs_count} parallel COFFE job(s).")
archive_entries = []
successes = 0
for i, job in enumerate(as_completed(jobs)):
    try:
        archive_entries.append(job.result())
        successes += 1
    except Exception as e:
        print("Got the following error during one of the job(s):")
        traceback.print_exc()
        print("")
    print(f"==> Finished job {i+1}/{jobs_count} ({successes} without errors)", end='\r')

output_path = os.path.join(output_dir, f"{args.output_file}.csv")
log(f"Now writing all results to {output_path}...")
pd.DataFrame.from_records(archive_entries).to_csv(output_path)
log(f"Completed -> {output_path}. Have a nice day!")